{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG1DuLrdcJmp",
        "outputId": "a226bab6-7b5e-469b-c331-20c4ec4899a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas scikit-learn tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpQdl4SFcaOe",
        "outputId": "ed0cfc18-8bec-4e35-8333-d2f554807d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kpi_label\n",
            "0    1385\n",
            "1     104\n",
            "2      11\n",
            "Name: count, dtype: int64\n",
            "Saved to ventilation_kpi_synthetic.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def generate_sample(n=1000):\n",
        "    temps = np.random.uniform(18, 32, size=n)       # 18–32 °C\n",
        "    hums  = np.random.uniform(30, 80, size=n)       # 30–80 %\n",
        "    co2   = np.random.uniform(400, 2000, size=n)    # 400–2000 ppm\n",
        "    airflow = np.random.uniform(0.0, 1.0, size=n)   # normalized 0–1\n",
        "\n",
        "    labels = []\n",
        "    for t, h, c, a in zip(temps, hums, co2, airflow):\n",
        "        if (c < 800 and 0.7 <= a <= 1.0 and 22 <= t <= 26 and 40 <= h <= 60):\n",
        "            labels.append(2)  # Good\n",
        "        elif (800 <= c <= 1200 and 0.4 <= a < 0.7):\n",
        "            labels.append(1)  # Moderate\n",
        "        else:\n",
        "            labels.append(0)  # Poor\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"temp\": temps,\n",
        "        \"humidity\": hums,\n",
        "        \"co2\": co2,\n",
        "        \"airflow\": airflow,\n",
        "        \"kpi_label\": labels\n",
        "    })\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = generate_sample(1500)\n",
        "    print(df[\"kpi_label\"].value_counts())\n",
        "    df.to_csv(\"ventilation_kpi_synthetic.csv\", index=False)\n",
        "    print(\"Saved to ventilation_kpi_synthetic.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7hiO4vGdGnO",
        "outputId": "f966f75e-b256-4b84-d7af-1e561d6ff037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        temp   humidity          co2   airflow  kpi_label\n",
            "0  23.243562  55.954089  1476.324791  0.599299          0\n",
            "1  31.310000  53.959094  1674.690236  0.513708          0\n",
            "2  28.247915  31.282103   800.748638  0.288185          0\n",
            "3  26.381219  47.062391  1399.798559  0.006464          0\n",
            "4  20.184261  49.009781  1314.793573  0.496239          0\n",
            "kpi_label\n",
            "0    1385\n",
            "1     104\n",
            "2      11\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"ventilation_kpi_synthetic.csv\")\n",
        "print(df.head())\n",
        "print(df[\"kpi_label\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DMve0WeVdMYo"
      },
      "outputs": [],
      "source": [
        "X = df[[\"temp\", \"humidity\", \"co2\", \"airflow\"]].values\n",
        "y = df[\"kpi_label\"].values  # 0,1,2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PwjpM1tJdN-c"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFgHjl1NdSbc",
        "outputId": "8edb846e-4d0b-4313-a3e7-af7d4d484a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Means: [2.50408589e+01 5.51482202e+01 1.18068923e+03 5.00866032e-01]\n",
            "Scales: [4.12939513e+00 1.44739619e+01 4.52279413e+02 2.88622975e-01]\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "# Save mean and std to use later in ESP32 / C code\n",
        "print(\"Means:\", scaler.mean_)\n",
        "print(\"Scales:\", scaler.scale_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MM_4w9vKdZgV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "kx6zfQmvdf7D",
        "outputId": "8249ac7f-b4eb-47dd-8552-c49cf56fad2d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m80\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m27\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">243</span> (972.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m243\u001b[0m (972.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">243</span> (972.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m243\u001b[0m (972.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_features = 4\n",
        "num_classes = 3\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(num_features,)),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GttFeGzpdp4A"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ToLmgFJdt6k",
        "outputId": "e0797ec9-08e5-414b-a36e-35340eb2d555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.0162 - loss: 1.3146 - val_accuracy: 0.1292 - val_loss: 1.1528\n",
            "Epoch 2/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2821 - loss: 1.0940 - val_accuracy: 0.7750 - val_loss: 0.9514\n",
            "Epoch 3/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8801 - loss: 0.8902 - val_accuracy: 0.8917 - val_loss: 0.7831\n",
            "Epoch 4/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9179 - loss: 0.7218 - val_accuracy: 0.8917 - val_loss: 0.6589\n",
            "Epoch 5/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9325 - loss: 0.5695 - val_accuracy: 0.8917 - val_loss: 0.5740\n",
            "Epoch 6/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9238 - loss: 0.4898 - val_accuracy: 0.8917 - val_loss: 0.5133\n",
            "Epoch 7/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9383 - loss: 0.3949 - val_accuracy: 0.8917 - val_loss: 0.4715\n",
            "Epoch 8/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9308 - loss: 0.3474 - val_accuracy: 0.8917 - val_loss: 0.4425\n",
            "Epoch 9/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9253 - loss: 0.3370 - val_accuracy: 0.8917 - val_loss: 0.4178\n",
            "Epoch 10/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9266 - loss: 0.3127 - val_accuracy: 0.8917 - val_loss: 0.4020\n",
            "Epoch 11/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9388 - loss: 0.2556 - val_accuracy: 0.8917 - val_loss: 0.3890\n",
            "Epoch 12/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9297 - loss: 0.2711 - val_accuracy: 0.8917 - val_loss: 0.3767\n",
            "Epoch 13/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9434 - loss: 0.2258 - val_accuracy: 0.8917 - val_loss: 0.3682\n",
            "Epoch 14/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9284 - loss: 0.2615 - val_accuracy: 0.8917 - val_loss: 0.3594\n",
            "Epoch 15/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9242 - loss: 0.2644 - val_accuracy: 0.8917 - val_loss: 0.3512\n",
            "Epoch 16/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9320 - loss: 0.2390 - val_accuracy: 0.8917 - val_loss: 0.3462\n",
            "Epoch 17/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9213 - loss: 0.2652 - val_accuracy: 0.8917 - val_loss: 0.3409\n",
            "Epoch 18/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9259 - loss: 0.2469 - val_accuracy: 0.8917 - val_loss: 0.3361\n",
            "Epoch 19/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9270 - loss: 0.2351 - val_accuracy: 0.8917 - val_loss: 0.3294\n",
            "Epoch 20/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9284 - loss: 0.2297 - val_accuracy: 0.8917 - val_loss: 0.3258\n",
            "Epoch 21/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9371 - loss: 0.2082 - val_accuracy: 0.8917 - val_loss: 0.3219\n",
            "Epoch 22/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9267 - loss: 0.2291 - val_accuracy: 0.8917 - val_loss: 0.3182\n",
            "Epoch 23/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9338 - loss: 0.2073 - val_accuracy: 0.8917 - val_loss: 0.3147\n",
            "Epoch 24/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9329 - loss: 0.2083 - val_accuracy: 0.8917 - val_loss: 0.3110\n",
            "Epoch 25/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9255 - loss: 0.2208 - val_accuracy: 0.8917 - val_loss: 0.3072\n",
            "Epoch 26/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9306 - loss: 0.2035 - val_accuracy: 0.8917 - val_loss: 0.3054\n",
            "Epoch 27/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9242 - loss: 0.2206 - val_accuracy: 0.8917 - val_loss: 0.3009\n",
            "Epoch 28/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9352 - loss: 0.1898 - val_accuracy: 0.8917 - val_loss: 0.2995\n",
            "Epoch 29/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9259 - loss: 0.2075 - val_accuracy: 0.8917 - val_loss: 0.2947\n",
            "Epoch 30/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9320 - loss: 0.1948 - val_accuracy: 0.8917 - val_loss: 0.2935\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS6uGQgmd0YW",
        "outputId": "f4754ac7-4b7e-448d-9907-ceeebe2d1a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.923\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CtccqIyld7mV"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(num_features,)),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1zG7LLKd_gf",
        "outputId": "16e46c40-6cf1-4ab4-d60e-2937b89ccdfa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"vent_kpi_ann.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_sieP6FeG9O",
        "outputId": "a3758ff4-1c09-47ed-ac0c-8dcbcf1395ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmpxmt1fghm'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_layer_1')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134169238473232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134169238474960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134169238474576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134169238478608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134169238476496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134169238480336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved vent_kpi_ann_float.tflite\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model(\"vent_kpi_ann.h5\")\n",
        "\n",
        "# Standard float model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"vent_kpi_ann_float.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Saved vent_kpi_ann_float.tflite\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLJ_Bz63ePzw",
        "outputId": "79ed6e5d-79a4-434c-addd-629e2370cb6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmp80l_bh46'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_layer_1')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134169238473232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134169238474960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134169238474576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134169238478608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134169238476496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134169238480336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved vent_kpi_ann_int8.tflite\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Use training data sample for calibration:\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"ventilation_kpi_synthetic.csv\")\n",
        "X = df[[\"temp\", \"humidity\", \"co2\", \"airflow\"]].values\n",
        "\n",
        "# Use same scaler:\n",
        "# Ideally reuse the saved mean/scale from training\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "def rep_data():\n",
        "    for i in range(100):\n",
        "        yield [X_scaled[i].astype(np.float32)]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = rep_data\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_quant = converter.convert()\n",
        "with open(\"vent_kpi_ann_int8.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_quant)\n",
        "\n",
        "print(\"Saved vent_kpi_ann_int8.tflite\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mldi_wLwedtj",
        "outputId": "5432e761-ed9f-4bf0-a019-368b436ab2d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True: 0, Pred: 2, Probs: [[0.2417114  0.17461458 0.5836741 ]]\n",
            "True: 0, Pred: 0, Probs: [[0.5520965  0.1833754  0.26452807]]\n",
            "True: 0, Pred: 0, Probs: [[0.6739437  0.16681258 0.15924372]]\n",
            "True: 0, Pred: 0, Probs: [[0.6106684  0.24756096 0.14177063]]\n",
            "True: 0, Pred: 2, Probs: [[0.17347205 0.1141322  0.7123958 ]]\n",
            "True: 0, Pred: 2, Probs: [[0.1851582  0.12217507 0.69266677]]\n",
            "True: 0, Pred: 2, Probs: [[0.08656234 0.03928419 0.87415344]]\n",
            "True: 0, Pred: 0, Probs: [[0.46408165 0.2514218  0.2844966 ]]\n",
            "True: 0, Pred: 2, Probs: [[0.3500033  0.23874286 0.41125384]]\n",
            "True: 0, Pred: 0, Probs: [[0.42958003 0.19706061 0.37335935]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load sample\n",
        "df = pd.read_csv(\"ventilation_kpi_synthetic.csv\")\n",
        "X = df[[\"temp\", \"humidity\", \"co2\", \"airflow\"]].values[:10]\n",
        "y = df[\"kpi_label\"].values[:10]\n",
        "\n",
        "# Use same scaler (here refit; later you'll hardcode)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Load float TFLite\n",
        "interpreter = tf.lite.Interpreter(model_path=\"vent_kpi_ann_float.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "for i in range(10):\n",
        "    sample = X_scaled[i:i+1].astype(np.float32)\n",
        "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    pred_class = np.argmax(output, axis=1)[0]\n",
        "    print(f\"True: {y[i]}, Pred: {pred_class}, Probs: {output}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpf5l7hsgSbn",
        "outputId": "b55efb50-e8da-4c72-9a15-f8a8166bf96a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Means: [2.52819143e+01 5.31536761e+01 1.26294437e+03 4.47437785e-01]\n",
            "Scales: [4.19519017e+00 9.37193782e+00 4.87982897e+02 2.82948308e-01]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['vent_kpi_scaler.pkl']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# After training, in train_ann_model.py\n",
        "print(\"Means:\", scaler.mean_)\n",
        "print(\"Scales:\", scaler.scale_)\n",
        "\n",
        "# Optional: save scaler using joblib\n",
        "import joblib\n",
        "joblib.dump(scaler, \"vent_kpi_scaler.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4V2rHDNUgVb5"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "scaler = joblib.load(\"vent_kpi_scaler.pkl\")\n",
        "\n",
        "df = pd.read_csv(\"ventilation_kpi_synthetic.csv\")\n",
        "X = df[[\"temp\", \"humidity\", \"co2\", \"airflow\"]].values[:100]  # use 100 samples now\n",
        "y = df[\"kpi_label\"].values[:100]\n",
        "\n",
        "X_scaled = scaler.transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERC3WjbygYrv",
        "outputId": "21215780-0d60-4e35-8c82-0d2197528e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TFLite accuracy over 100 samples: 0.320\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = len(X_scaled)\n",
        "\n",
        "for i in range(total):\n",
        "    sample = X_scaled[i:i+1].astype(np.float32)\n",
        "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    pred_class = np.argmax(output, axis=1)[0]\n",
        "\n",
        "    if pred_class == y[i]:\n",
        "        correct += 1\n",
        "\n",
        "tflite_acc = correct / total\n",
        "print(f\"TFLite accuracy over {total} samples: {tflite_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyIjSPivhmYN",
        "outputId": "9f7cbca1-a249-47bb-b465-6abc1701720c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step\n",
            "Keras accuracy on 100-sample subset: 0.320\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 1) Load data\n",
        "df = pd.read_csv(\"ventilation_kpi_synthetic.csv\")\n",
        "X = df[[\"temp\", \"humidity\", \"co2\", \"airflow\"]].values\n",
        "y = df[\"kpi_label\"].values\n",
        "\n",
        "# To make it fair, randomly choose 100 samples:\n",
        "np.random.seed(42)\n",
        "indices = np.random.choice(len(X), size=100, replace=False)\n",
        "X_sample = X[indices]\n",
        "y_sample = y[indices]\n",
        "\n",
        "# 2) Load scaler used during training\n",
        "scaler = joblib.load(\"vent_kpi_scaler.pkl\")\n",
        "X_scaled = scaler.transform(X_sample)\n",
        "\n",
        "# 3) Evaluate original Keras model\n",
        "keras_model = tf.keras.models.load_model(\"vent_kpi_ann.h5\")\n",
        "keras_probs = keras_model.predict(X_scaled)\n",
        "keras_preds = np.argmax(keras_probs, axis=1)\n",
        "keras_acc = np.mean(keras_preds == y_sample)\n",
        "print(f\"Keras accuracy on 100-sample subset: {keras_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zi3vmLMh67o",
        "outputId": "d2e0134c-f892-49ef-fbd8-28ebd78bda5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kpi_label\n",
            "0    0.923333\n",
            "1    0.069333\n",
            "2    0.007333\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"kpi_label\"].value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQdPf3SVjRPD",
        "outputId": "81e63537-b3be-459f-9577-a788245b12fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kpi_label\n",
            "0    0.333333\n",
            "1    0.333333\n",
            "2    0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Saved to ventilation_kpi_balanced.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def generate_poor(n=500):\n",
        "    temps = np.random.uniform(18, 32, size=n)\n",
        "    hums  = np.random.uniform(30, 80, size=n)\n",
        "    co2   = np.random.uniform(1200, 2000, size=n)      # high CO2\n",
        "    airflow = np.random.uniform(0.0, 0.4, size=n)      # low airflow\n",
        "\n",
        "    labels = np.zeros(n, dtype=int)  # 0 = Poor\n",
        "    return temps, hums, co2, airflow, labels\n",
        "\n",
        "def generate_moderate(n=500):\n",
        "    temps = np.random.uniform(20, 30, size=n)\n",
        "    hums  = np.random.uniform(35, 75, size=n)\n",
        "    co2   = np.random.uniform(800, 1400, size=n)       # mid CO2\n",
        "    airflow = np.random.uniform(0.3, 0.7, size=n)      # medium airflow\n",
        "\n",
        "    labels = np.ones(n, dtype=int)   # 1 = Moderate\n",
        "    return temps, hums, co2, airflow, labels\n",
        "\n",
        "def generate_good(n=500):\n",
        "    temps = np.random.uniform(22, 26, size=n)\n",
        "    hums  = np.random.uniform(40, 60, size=n)\n",
        "    co2   = np.random.uniform(400, 800, size=n)        # low CO2\n",
        "    airflow = np.random.uniform(0.7, 1.0, size=n)      # high airflow\n",
        "\n",
        "    labels = np.full(n, 2, dtype=int)  # 2 = Good\n",
        "    return temps, hums, co2, airflow, labels\n",
        "\n",
        "def make_balanced_dataset(n_per_class=500):\n",
        "    t0, h0, c0, a0, y0 = generate_poor(n_per_class)\n",
        "    t1, h1, c1, a1, y1 = generate_moderate(n_per_class)\n",
        "    t2, h2, c2, a2, y2 = generate_good(n_per_class)\n",
        "\n",
        "    temps = np.concatenate([t0, t1, t2])\n",
        "    hums  = np.concatenate([h0, h1, h2])\n",
        "    co2   = np.concatenate([c0, c1, c2])\n",
        "    airflow = np.concatenate([a0, a1, a2])\n",
        "    labels  = np.concatenate([y0, y1, y2])\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"temp\": temps,\n",
        "        \"humidity\": hums,\n",
        "        \"co2\": co2,\n",
        "        \"airflow\": airflow,\n",
        "        \"kpi_label\": labels\n",
        "    })\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = make_balanced_dataset(500)\n",
        "    print(df[\"kpi_label\"].value_counts(normalize=True))\n",
        "    df.to_csv(\"ventilation_kpi_balanced.csv\", index=False)\n",
        "    print(\"Saved to ventilation_kpi_balanced.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-ISCvb0jfW-",
        "outputId": "b1749210-c48b-4a1e-b5f5-b260eb6a9c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kpi_label\n",
            "0    0.333333\n",
            "1    0.333333\n",
            "2    0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Saved scaler to vent_kpi_scaler.pkl\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.3016 - loss: 1.2125 - val_accuracy: 0.4667 - val_loss: 1.0792\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5192 - loss: 1.0461 - val_accuracy: 0.7792 - val_loss: 0.9062\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8075 - loss: 0.8596 - val_accuracy: 0.7875 - val_loss: 0.6813\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8056 - loss: 0.6593 - val_accuracy: 0.8625 - val_loss: 0.4911\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8603 - loss: 0.4766 - val_accuracy: 0.9125 - val_loss: 0.3634\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9226 - loss: 0.3386 - val_accuracy: 0.9333 - val_loss: 0.2682\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9225 - loss: 0.2714 - val_accuracy: 0.9458 - val_loss: 0.1931\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9435 - loss: 0.2009 - val_accuracy: 0.9583 - val_loss: 0.1472\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9570 - loss: 0.1451 - val_accuracy: 0.9708 - val_loss: 0.1178\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9567 - loss: 0.1192 - val_accuracy: 0.9750 - val_loss: 0.0990\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9578 - loss: 0.1060 - val_accuracy: 0.9750 - val_loss: 0.0850\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.0889 - val_accuracy: 0.9750 - val_loss: 0.0803\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9687 - loss: 0.0846 - val_accuracy: 0.9792 - val_loss: 0.0744\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.0719 - val_accuracy: 0.9750 - val_loss: 0.0714\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9782 - loss: 0.0621 - val_accuracy: 0.9667 - val_loss: 0.0693\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0593 - val_accuracy: 0.9708 - val_loss: 0.0652\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9706 - loss: 0.0673 - val_accuracy: 0.9667 - val_loss: 0.0654\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.0537 - val_accuracy: 0.9667 - val_loss: 0.0655\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.973\n",
            "Saved model to vent_kpi_ann.h5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 1) Load balanced dataset\n",
        "df = pd.read_csv(\"ventilation_kpi_balanced.csv\")\n",
        "print(df[\"kpi_label\"].value_counts(normalize=True))\n",
        "\n",
        "X = df[[\"temp\", \"humidity\", \"co2\", \"airflow\"]].values\n",
        "y = df[\"kpi_label\"].values\n",
        "\n",
        "# 2) Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "joblib.dump(scaler, \"vent_kpi_scaler.pkl\")\n",
        "print(\"Saved scaler to vent_kpi_scaler.pkl\")\n",
        "\n",
        "# 4) Model\n",
        "num_features = 4\n",
        "num_classes = 3\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(num_features,)),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "callback = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "\n",
        "model.save(\"vent_kpi_ann.h5\")\n",
        "print(\"Saved model to vent_kpi_ann.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzHyFYujjmk6",
        "outputId": "6d1d9cdc-b719-4593-bbe3-da4891853055"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Keras accuracy on 300-sample subset: 0.967\n",
            "Input details: [{'name': 'serving_default_input_layer_1:0', 'index': 0, 'shape': array([1, 4], dtype=int32), 'shape_signature': array([-1,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "Output details: [{'name': 'StatefulPartitionedCall_1:0', 'index': 7, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([-1,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "TFLite accuracy on 300-sample subset: 0.470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "df = pd.read_csv(\"ventilation_kpi_balanced.csv\")\n",
        "X = df[[\"temp\", \"humidity\", \"co2\", \"airflow\"]].values\n",
        "y = df[\"kpi_label\"].values\n",
        "\n",
        "np.random.seed(42)\n",
        "indices = np.random.choice(len(X), size=300, replace=False)\n",
        "X_sample = X[indices]\n",
        "y_sample = y[indices]\n",
        "\n",
        "scaler = joblib.load(\"vent_kpi_scaler.pkl\")\n",
        "X_scaled = scaler.transform(X_sample)\n",
        "\n",
        "# Keras model\n",
        "keras_model = tf.keras.models.load_model(\"vent_kpi_ann.h5\")\n",
        "keras_probs = keras_model.predict(X_scaled)\n",
        "keras_preds = np.argmax(keras_probs, axis=1)\n",
        "keras_acc = np.mean(keras_preds == y_sample)\n",
        "print(f\"Keras accuracy on 300-sample subset: {keras_acc:.3f}\")\n",
        "\n",
        "# TFLite float model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"vent_kpi_ann_float.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input details:\", input_details)\n",
        "print(\"Output details:\", output_details)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "for i in range(len(X_scaled)):\n",
        "    sample = X_scaled[i:i+1].astype(np.float32)\n",
        "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    pred_class = np.argmax(output, axis=1)[0]\n",
        "    if pred_class == y_sample[i]:\n",
        "        correct += 1\n",
        "\n",
        "tflite_acc = correct / len(X_scaled)\n",
        "print(f\"TFLite accuracy on 300-sample subset: {tflite_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRBChNVo0Fxl",
        "outputId": "62f8ad99-919b-48ed-f39f-561748a55385"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
            "=== Keras predictions ===\n",
            "True: 2, Pred: 2, Probs: [4.8588108e-06 2.6566868e-03 9.9733847e-01]\n",
            "True: 2, Pred: 2, Probs: [1.2085118e-05 3.8274087e-03 9.9616045e-01]\n",
            "True: 0, Pred: 1, Probs: [0.36798218 0.6256703  0.00634748]\n",
            "True: 0, Pred: 0, Probs: [0.9184234  0.07556049 0.00601604]\n",
            "True: 0, Pred: 0, Probs: [0.9966864  0.00225001 0.00106363]\n",
            "True: 1, Pred: 1, Probs: [0.00329261 0.94542724 0.05128022]\n",
            "True: 2, Pred: 2, Probs: [1.0596546e-05 8.1666773e-03 9.9182278e-01]\n",
            "True: 1, Pred: 1, Probs: [0.0028445 0.9779547 0.0192008]\n",
            "True: 2, Pred: 2, Probs: [9.4617817e-06 5.5967807e-03 9.9439371e-01]\n",
            "True: 0, Pred: 0, Probs: [0.98515815 0.01373827 0.00110361]\n",
            "\n",
            "Input details: [{'name': 'serving_default_input_layer_1:0', 'index': 0, 'shape': array([1, 4], dtype=int32), 'shape_signature': array([-1,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "Output details: [{'name': 'StatefulPartitionedCall_1:0', 'index': 7, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([-1,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "\n",
            "=== TFLite predictions ===\n",
            "True: 2, Pred: 0, Probs: [0.40098187 0.21371296 0.3853052 ]\n",
            "True: 2, Pred: 2, Probs: [0.2184348  0.16327153 0.6182937 ]\n",
            "True: 0, Pred: 2, Probs: [0.25530666 0.21017112 0.53452224]\n",
            "True: 0, Pred: 0, Probs: [0.55511534 0.27081695 0.17406766]\n",
            "True: 0, Pred: 0, Probs: [0.47572502 0.32037836 0.20389651]\n",
            "True: 1, Pred: 2, Probs: [0.31047112 0.26981288 0.41971597]\n",
            "True: 2, Pred: 2, Probs: [0.24880415 0.19993505 0.55126077]\n",
            "True: 1, Pred: 2, Probs: [0.1375792  0.08234916 0.7800716 ]\n",
            "True: 2, Pred: 2, Probs: [0.25796664 0.21348906 0.52854425]\n",
            "True: 0, Pred: 2, Probs: [0.21613826 0.15870062 0.6251611 ]\n",
            "\n",
            "Keras acc on 10-sample subset: 0.900\n",
            "TFLite acc on 10-sample subset: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "\n",
        "# 1) Load balanced data\n",
        "df = pd.read_csv(\"ventilation_kpi_balanced.csv\")\n",
        "X = df[[\"temp\", \"humidity\", \"co2\", \"airflow\"]].values\n",
        "y = df[\"kpi_label\"].values\n",
        "\n",
        "# pick a fixed subset\n",
        "np.random.seed(42)\n",
        "indices = np.random.choice(len(X), size=10, replace=False)\n",
        "X_sample = X[indices]\n",
        "y_sample = y[indices]\n",
        "\n",
        "# 2) Load scaler (same used in training)\n",
        "scaler = joblib.load(\"vent_kpi_scaler.pkl\")\n",
        "X_scaled = scaler.transform(X_sample)\n",
        "\n",
        "# 3) Load Keras model\n",
        "keras_model = tf.keras.models.load_model(\"vent_kpi_ann.h5\")\n",
        "keras_probs = keras_model.predict(X_scaled)\n",
        "keras_preds = np.argmax(keras_probs, axis=1)\n",
        "\n",
        "print(\"=== Keras predictions ===\")\n",
        "for i in range(10):\n",
        "    print(f\"True: {y_sample[i]}, Pred: {keras_preds[i]}, Probs: {keras_probs[i]}\")\n",
        "\n",
        "# 4) Load TFLite model (FLOAT version)\n",
        "interpreter = tf.lite.Interpreter(model_path=\"vent_kpi_ann_float.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"\\nInput details:\", input_details)\n",
        "print(\"Output details:\", output_details)\n",
        "\n",
        "print(\"\\n=== TFLite predictions ===\")\n",
        "tflite_preds = []\n",
        "for i in range(10):\n",
        "    sample = X_scaled[i:i+1].astype(np.float32)\n",
        "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    pred_class = np.argmax(output, axis=1)[0]\n",
        "    tflite_preds.append(pred_class)\n",
        "    print(f\"True: {y_sample[i]}, Pred: {pred_class}, Probs: {output[0]}\")\n",
        "\n",
        "# 5) Quick accuracies on this subset\n",
        "keras_acc = np.mean(keras_preds == y_sample)\n",
        "tflite_acc = np.mean(np.array(tflite_preds) == y_sample)\n",
        "print(f\"\\nKeras acc on 10-sample subset: {keras_acc:.3f}\")\n",
        "print(f\"TFLite acc on 10-sample subset: {tflite_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liBRDtB51RuJ",
        "outputId": "73ba5a18-5f03-42ac-be8b-d59e91815e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution:\n",
            "kpi_label\n",
            "0    0.333333\n",
            "1    0.333333\n",
            "2    0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Saved scaler to vent_kpi_scaler.pkl\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.3482 - loss: 1.0869 - val_accuracy: 0.6042 - val_loss: 0.9315\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.6187 - loss: 0.9098 - val_accuracy: 0.6958 - val_loss: 0.7516\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6896 - loss: 0.7189 - val_accuracy: 0.7000 - val_loss: 0.5950\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6899 - loss: 0.5829 - val_accuracy: 0.7125 - val_loss: 0.4902\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7391 - loss: 0.4872 - val_accuracy: 0.7875 - val_loss: 0.4146\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8273 - loss: 0.4071 - val_accuracy: 0.9167 - val_loss: 0.3120\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9181 - loss: 0.3013 - val_accuracy: 0.9417 - val_loss: 0.2172\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9546 - loss: 0.2201 - val_accuracy: 0.9500 - val_loss: 0.1622\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9531 - loss: 0.1574 - val_accuracy: 0.9750 - val_loss: 0.1222\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9711 - loss: 0.1099 - val_accuracy: 0.9667 - val_loss: 0.1055\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9635 - loss: 0.1105 - val_accuracy: 0.9708 - val_loss: 0.0922\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9592 - loss: 0.1021 - val_accuracy: 0.9750 - val_loss: 0.0837\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9640 - loss: 0.0927 - val_accuracy: 0.9708 - val_loss: 0.0794\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9680 - loss: 0.0816 - val_accuracy: 0.9750 - val_loss: 0.0751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Keras test accuracy: 0.957\n",
            "Saved model to vent_kpi_ann.h5\n",
            "Saved artifact at '/tmp/tmp3cl2y29r'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 4), dtype=tf.float32, name='keras_tensor_45')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134168275264784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134168275259792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134168275258448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134168275260752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134168275256912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134168275260368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134168275261904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134168275262480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved vent_kpi_ann_float.tflite\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 1) Load balanced dataset\n",
        "df = pd.read_csv(\"ventilation_kpi_balanced.csv\")\n",
        "print(\"Class distribution:\")\n",
        "print(df[\"kpi_label\"].value_counts(normalize=True))\n",
        "\n",
        "X = df[[\"temp\", \"humidity\", \"co2\", \"airflow\"]].values\n",
        "y = df[\"kpi_label\"].values\n",
        "\n",
        "# 2) Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Standardize\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "joblib.dump(scaler, \"vent_kpi_scaler.pkl\")\n",
        "print(\"Saved scaler to vent_kpi_scaler.pkl\")\n",
        "\n",
        "# 4) Define model\n",
        "num_features = 4\n",
        "num_classes = 3\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(num_features,)),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "callback = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"Final Keras test accuracy: {test_acc:.3f}\")\n",
        "\n",
        "# 5) Save Keras model\n",
        "model.save(\"vent_kpi_ann.h5\")\n",
        "print(\"Saved model to vent_kpi_ann.h5\")\n",
        "\n",
        "# 6) Convert THIS SAME MODEL instance to TFLite (float)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "with open(\"vent_kpi_ann_float.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Saved vent_kpi_ann_float.tflite\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q3WBZf81sOs",
        "outputId": "4bc28460-acc3-4f6e-a8ca-63e42ce324df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TFLite model: vent_kpi_ann_float.tflite\n",
            "Using scaler: vent_kpi_scaler.pkl\n"
          ]
        }
      ],
      "source": [
        "print(\"Using TFLite model: vent_kpi_ann_float.tflite\")\n",
        "print(\"Using scaler: vent_kpi_scaler.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht5F0RSG3kCJ",
        "outputId": "ef5a0df3-b2ab-46ca-e2de-5da17420c4c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TFLite model: vent_kpi_ann_float.tflite\n",
            "Using scaler: vent_kpi_scaler.pkl\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
            "=== Keras predictions ===\n",
            "True: 2, Pred: 2, Probs: [2.8285987e-05 1.1964604e-02 9.8800713e-01]\n",
            "True: 2, Pred: 2, Probs: [5.8625450e-05 1.6538963e-02 9.8340243e-01]\n",
            "True: 0, Pred: 1, Probs: [0.3265195  0.65673494 0.01674562]\n",
            "True: 0, Pred: 0, Probs: [0.91585314 0.07898689 0.00515999]\n",
            "True: 0, Pred: 0, Probs: [9.8690325e-01 1.2804362e-02 2.9233139e-04]\n",
            "True: 1, Pred: 1, Probs: [0.0206587 0.7586871 0.2206542]\n",
            "True: 2, Pred: 2, Probs: [1.6046451e-04 4.0786415e-02 9.5905322e-01]\n",
            "True: 1, Pred: 1, Probs: [0.00372432 0.93849725 0.05777847]\n",
            "True: 2, Pred: 2, Probs: [1.5004676e-04 3.0441247e-02 9.6940875e-01]\n",
            "True: 0, Pred: 0, Probs: [9.5589375e-01 4.3462984e-02 6.4328336e-04]\n",
            "\n",
            "Input details: [{'name': 'serving_default_keras_tensor_45:0', 'index': 0, 'shape': array([1, 4], dtype=int32), 'shape_signature': array([-1,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "Output details: [{'name': 'StatefulPartitionedCall_1:0', 'index': 13, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([-1,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "\n",
            "=== TFLite predictions ===\n",
            "True: 2, Pred: 2, Probs: [2.8285986e-05 1.1964603e-02 9.8800707e-01]\n",
            "True: 2, Pred: 2, Probs: [5.8625395e-05 1.6538963e-02 9.8340249e-01]\n",
            "True: 0, Pred: 1, Probs: [0.3265194  0.65673494 0.01674561]\n",
            "True: 0, Pred: 0, Probs: [0.9158532  0.07898688 0.00516   ]\n",
            "True: 0, Pred: 0, Probs: [9.86903310e-01 1.28043555e-02 2.92331388e-04]\n",
            "True: 1, Pred: 1, Probs: [0.0206587  0.758687   0.22065425]\n",
            "True: 2, Pred: 2, Probs: [1.6046433e-04 4.0786441e-02 9.5905310e-01]\n",
            "True: 1, Pred: 1, Probs: [0.00372432 0.9384972  0.05777847]\n",
            "True: 2, Pred: 2, Probs: [1.5004676e-04 3.0441225e-02 9.6940875e-01]\n",
            "True: 0, Pred: 0, Probs: [9.5589375e-01 4.3462977e-02 6.4328394e-04]\n",
            "\n",
            "Keras acc on 10-sample subset: 0.900\n",
            "TFLite acc on 10-sample subset: 0.900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"Using TFLite model: vent_kpi_ann_float.tflite\")\n",
        "print(\"Using scaler: vent_kpi_scaler.pkl\")\n",
        "\n",
        "# 1) Load data\n",
        "df = pd.read_csv(\"ventilation_kpi_balanced.csv\")\n",
        "X = df[[\"temp\", \"humidity\", \"co2\", \"airflow\"]].values\n",
        "y = df[\"kpi_label\"].values\n",
        "\n",
        "# choose a subset for debugging\n",
        "np.random.seed(42)\n",
        "indices = np.random.choice(len(X), size=10, replace=False)\n",
        "X_sample = X[indices]\n",
        "y_sample = y[indices]\n",
        "\n",
        "# 2) Load scaler\n",
        "scaler = joblib.load(\"vent_kpi_scaler.pkl\")\n",
        "X_scaled = scaler.transform(X_sample)\n",
        "\n",
        "# 3) Keras model\n",
        "keras_model = tf.keras.models.load_model(\"vent_kpi_ann.h5\")\n",
        "keras_probs = keras_model.predict(X_scaled)\n",
        "keras_preds = np.argmax(keras_probs, axis=1)\n",
        "\n",
        "print(\"=== Keras predictions ===\")\n",
        "for i in range(10):\n",
        "    print(f\"True: {y_sample[i]}, Pred: {keras_preds[i]}, Probs: {keras_probs[i]}\")\n",
        "\n",
        "# 4) TFLite model (FLOAT)\n",
        "interpreter = tf.lite.Interpreter(model_path=\"vent_kpi_ann_float.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"\\nInput details:\", input_details)\n",
        "print(\"Output details:\", output_details)\n",
        "\n",
        "print(\"\\n=== TFLite predictions ===\")\n",
        "tflite_preds = []\n",
        "for i in range(10):\n",
        "    sample = X_scaled[i:i+1].astype(np.float32)\n",
        "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    pred_class = np.argmax(output, axis=1)[0]\n",
        "    tflite_preds.append(pred_class)\n",
        "    print(f\"True: {y_sample[i]}, Pred: {pred_class}, Probs: {output[0]}\")\n",
        "\n",
        "keras_acc = np.mean(keras_preds == y_sample)\n",
        "tflite_acc = np.mean(np.array(tflite_preds) == y_sample)\n",
        "print(f\"\\nKeras acc on 10-sample subset: {keras_acc:.3f}\")\n",
        "print(f\"TFLite acc on 10-sample subset: {tflite_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lc_mXdG63xCw",
        "outputId": "bc0fae21-dc9b-47f4-c83f-875273b77d4a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_88781365-a2db-49f7-bd83-0d856650451a\", \"vent_kpi_ann_float.tflite\", 5908)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4318a970-0733-4470-b1ac-7132094d93e2\", \"vent_kpi_scaler.pkl\", 711)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_b81d6960-e0f7-455b-bb29-7bfcbfc929a8\", \"ventilation_kpi_balanced.csv\", 114719)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_89f268bc-36f0-4477-af8d-f5bca3d7172b\", \"vent_kpi_ann.h5\", 46584)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"vent_kpi_ann_float.tflite\")\n",
        "files.download(\"vent_kpi_scaler.pkl\")\n",
        "files.download(\"ventilation_kpi_balanced.csv\")\n",
        "files.download(\"vent_kpi_ann.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9xP1mL132Bq",
        "outputId": "20f575f5-cfdb-47ed-91bd-40525090c469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
